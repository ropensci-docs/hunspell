[{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"spell-checking","dir":"Articles","previous_headings":"","what":"Spell Checking","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"Spell checking text consists following steps: Parse document extracting (tokenizing) words want check Analyze word breaking ’s root (stemming) conjugation affix Lookup dictionary word+affix combination valid language (optional) incorrect words, suggest corrections finding similar (correct) words dictionary can steps manually Hunspell automatically.","code":""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"check-individual-words","dir":"Articles","previous_headings":"Spell Checking","what":"Check Individual Words","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"hunspell_check hunspell_suggest functions can test individual words correctness, suggest similar (correct) words look similar given (incorrect) word.","code":"library(hunspell)  # Check individual words words <- c(\"beer\", \"wiskey\", \"wine\") correct <- hunspell_check(words) print(correct) [1]  TRUE FALSE  TRUE # Find suggestions for incorrect words hunspell_suggest(words[!correct]) [[1]] [1] \"whiskey\"  \"whiskery\""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"check-documents","dir":"Articles","previous_headings":"Spell Checking","what":"Check Documents","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"practice often want spell check entire document searching incorrect words. done using hunspell function: Besides plain text, hunspell supports various document formats, html latex:","code":"bad <- hunspell(\"spell checkers are not neccessairy for langauge ninjas\") print(bad[[1]]) [1] \"neccessairy\" \"langauge\" hunspell_suggest(bad[[1]]) [[1]] [1] \"necessary\"   \"necessarily\"  [[2]] [1] \"language\" \"melange\" download.file(\"https://arxiv.org/e-print/1406.4806v1\", \"1406.4806v1.tar.gz\",  mode = \"wb\") untar(\"1406.4806v1.tar.gz\", \"content.tex\") text <- readLines(\"content.tex\", warn = FALSE) bad_words <- hunspell(text, format = \"latex\") sort(unique(unlist(bad_words))) [1] \"auth\"              \"CORBA\"             \"cpu\"                [4] \"cran\"              \"cron\"              \"css\"                [7] \"csv\"               \"CTRL\"              \"DCOM\"              [10] \"de\"                \"dec\"               \"decompositions\"    [13] \"dir\"               \"DOM\"               \"DSL\"               [16] \"eol\"               \"ESC\"               \"facto\"             [19] \"grDevices\"         \"httpuv\"            \"ignorable\"         [22] \"interoperable\"     \"JRI\"               \"js\"                [25] \"json\"              \"jsonlite\"          \"knitr\"             [28] \"md\"                \"memcached\"         \"mydata\"            [31] \"myfile\"            \"NaN\"               \"nondegenerateness\" [34] \"OAuth\"             \"ocpu\"              \"opencpu\"           [37] \"OpenCPU\"           \"pandoc\"            \"pb\"                [40] \"php\"               \"png\"               \"prescripted\"       [43] \"priori\"            \"protobuf\"          \"rApache\"           [46] \"rda\"               \"rds\"               \"reproducibility\"   [49] \"Reproducibility\"   \"RinRuby\"           \"RInside\"           [52] \"rlm\"               \"rmd\"               \"rnorm\"             [55] \"rnw\"               \"RPC\"               \"RProtoBuf\"         [58] \"rpy\"               \"Rserve\"            \"RStudio\"           [61] \"saveRDS\"           \"scalability\"       \"scalable\"          [64] \"schemas\"           \"se\"                \"sep\"               [67] \"SIGINT\"            \"STATA\"             \"stateful\"          [70] \"Stateful\"          \"statefulness\"      \"stdout\"            [73] \"STDOUT\"            \"suboptimal\"        \"svg\"               [76] \"sweave\"            \"tex\"               \"texi\"              [79] \"tmp\"               \"toJSON\"            \"urlencoded\"        [82] \"www\"               \"xyz\""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"check-pdf-files","dir":"Articles","previous_headings":"Spell Checking","what":"Check PDF files","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"Use text-extraction pdftools package spell check text PDF files!","code":"text <- pdftools::pdf_text('https://www.gnu.org/licenses/quick-guide-gplv3.pdf') bad_words <- hunspell(text) sort(unique(unlist(bad_words))) [1] \"Affero\"        \"AGPLed\"        \"cryptographic\" \"DRM\"            [5] \"fsf\"           \"GPLed\"         \"GPLv\"          \"ISC\"            [9] \"OpenSolaris’\"  \"opments\"       \"tivoization\"   \"Tivoization\"   [13] \"tributing\"     \"users’\""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"check-manual-pages","dir":"Articles","previous_headings":"Spell Checking","what":"Check Manual Pages","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"spelling package builds hunspell wrapper spell-check manual pages R packages. Results might contain lot false positives technical jargon, might also catch typo two. Point root source package:","code":"spelling::spell_check_package(\"~/workspace/V8\") WORD          FOUND IN ECMA          V8.Rd:16, description:2,4 ECMAScript    description:2 emscripten    description:5 htmlwidgets   JS.Rd:16 JSON          V8.Rd:33,38,39,57,58,59,120 jsonlite      V8.Rd:42 Ooms          V8.Rd:41,120 Xie           JS.Rd:26 Yihui         JS.Rd:26"},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"morphological-analysis","dir":"Articles","previous_headings":"","what":"Morphological Analysis","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"order lookup word dictionary, hunspell needs break stem (stemming) conjugation affix. hunspell function automatically can also manually.","code":""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"stemming-words","dir":"Articles","previous_headings":"Morphological Analysis","what":"Stemming Words","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"hunspell_stem looks words dictionary match root given word. Note function returns list words can multiple matches.","code":"# Stemming words <- c(\"love\", \"loving\", \"lovingly\", \"loved\", \"lover\", \"lovely\") hunspell_stem(words) [[1]] [1] \"love\"  [[2]] [1] \"loving\" \"love\"    [[3]] [1] \"loving\"  [[4]] [1] \"loved\" \"love\"   [[5]] [1] \"lover\" \"love\"   [[6]] [1] \"lovely\" \"love\""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"analyzing-words","dir":"Articles","previous_headings":"Morphological Analysis","what":"Analyzing Words","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"hunspell_analyze function similar, returns stem affix syntax word:","code":"hunspell_analyze(words) [[1]] [1] \" st:love\"  [[2]] [1] \" st:loving\"    \" st:love fl:G\"  [[3]] [1] \" st:loving fl:Y\"  [[4]] [1] \" st:loved\"     \" st:love fl:D\"  [[5]] [1] \" st:lover\"     \" st:love fl:R\"  [[6]] [1] \" st:lovely\"    \" st:love fl:Y\""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"tokenizing","dir":"Articles","previous_headings":"","what":"Tokenizing","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"support spell checking documents, Hunspell includes parsers various document formats, including text, html, xml, man latex. Hunspell package also exposes tokenizers directly can used application spell checking.","code":"text <- readLines(\"content.tex\", warn = FALSE) allwords <- hunspell_parse(text, format = \"latex\")  # Third line (title) only print(allwords[[3]]) [1] \"The\"        \"OpenCPU\"    \"System\"     \"Towards\"    \"a\"           [6] \"Universal\"  \"Interface\"  \"for\"        \"Scientific\" \"Computing\"  [11] \"through\"    \"Separation\" \"of\"         \"Concerns\""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"summarizing-text","dir":"Articles","previous_headings":"Tokenizing","what":"Summarizing Text","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"text analysis often want summarize text via ’s stems. example can count words display wordcloud: stop words. Let’s filter :","code":"allwords <- hunspell_parse(janeaustenr::prideprejudice) stems <- unlist(hunspell_stem(unlist(allwords))) words <- sort(table(stems), decreasing = TRUE) print(head(words, 30)) stems       the        to        of       and         a         i         h         I       4402      4305      3611      3585      3135      2929      2233      2069         in       was       she        it      that       not       you        he       1881      1846      1711      1640      1579      1429      1366      1336         hi        be       had        Mr       for      with       but      have       1271      1241      1177      1129      1064      1053      1002       938         on        at       him        my        by Elizabeth        931       787       764       719       636       635 df <- as.data.frame(words) df$stems <- as.character(df$stems) stops <- df$stems %in% stopwords::stopwords(source=\"stopwords-iso\") wcdata <- head(df[!stops,], 150) print(wcdata, max = 40) stems Freq 8           I 2069 20         Mr 1129 30  Elizabeth  635 48      Darcy  418 63     sister  294 64       Jane  292 68       Miss  281 72       lady  265 76         It  247 79         He  235 85       time  224 87         ha  221 96        aft  200 105     happy  183 107   Collins  180 112       bee  175 115       day  174 117     Lydia  171 119      feel  167 120    friend  166  [ reached 'max' / getOption(\"max.print\") -- omitted 130 rows ] library(wordcloud2) names(wcdata) <- c(\"word\", \"freq\") wcdata$freq <- (wcdata$freq)^(2/3) wordcloud2(wcdata)"},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"hunspell-dictionaries","dir":"Articles","previous_headings":"","what":"Hunspell Dictionaries","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"Hunspell based MySpell backward-compatible MySpell aspell dictionaries. Chances dictionaries language already available system! Hunspell dictionary consists two files: [lang].aff file specifies affix syntax language [lang].dic file contains wordlist formatted using syntax aff file. Typically files located directory share filename, example en_GB.aff en_GB.dic. list_dictionaries() function lists available dictionaries current directory standard system paths dictionaries usually installed. dictionary function used load available dictionaries: files one standard paths can also specify full path either dic aff file:","code":"list_dictionaries() [1] \"en_GB\" \"en_US\" dictionary(\"en_GB\") <hunspell dictionary>  affix: /usr/local/lib/R/site-library/hunspell/dict/en_GB.aff   dictionary: /usr/local/lib/R/site-library/hunspell/dict/en_GB.dic   encoding: UTF-8   wordchars: ’   added: 0 custom words dutch <- dictionary(\"~/workspace/Dictionaries/Dutch.dic\") print(dutch) <hunspell dictionary>  affix: /Users/jeroen/workspace/Dictionaries/Dutch.aff   dictionary: /Users/jeroen/workspace/Dictionaries/Dutch.dic   encoding: UTF-8   wordchars: '-./0123456789\\ĳ’"},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"setting-a-language","dir":"Articles","previous_headings":"Hunspell Dictionaries","what":"Setting a Language","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"hunspell R package includes dictionaries en_US en_GB. don’t speak en_US can always switch British English: want use another language need make sure dictionary available system. dictionary function used read dictionary. Note dict argument string, passed dictionary function.","code":"hunspell(\"My favourite colour to visualise is grey\") [[1]] [1] \"favourite\" \"colour\"    \"visualise\" \"grey\" hunspell(\"My favourite colour to visualise is grey\", dict = 'en_GB') [[1]] character(0) dutch <- dictionary(\"~/workspace/Dictionaries/Dutch.dic\") hunspell(\"Hij heeft de klok wel horen luiden, maar weet niet waar de klepel hangt\", dict = dutch)"},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"installing-dictionaries-in-rstudio","dir":"Articles","previous_headings":"Hunspell Dictionaries","what":"Installing Dictionaries in RStudio","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"RStudio users can install various dictionaries via “Global Options” menu IDE. dictionaries installed become available hunspell spelling package well.","code":""},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"dictionaries-on-linux","dir":"Articles","previous_headings":"Hunspell Dictionaries","what":"Dictionaries on Linux","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"best way install dictionaries Linux via system package manager. example like install Austrian-German dictionary Debian Ubuntu either need hunspell-de-myspell-de-package: Fedora CentOS / RHEL German dialects included hunspell-de package installing able load dictionary: didn’t work, verify dictionary files installed one system directories (usually /usr/share/myspell /usr/share/hunspell).","code":"sudo apt-get install hunspell-de-at sudo yum install hunspell-de dict <- dictionary('de_AT')"},{"path":"https://docs.ropensci.org/hunspell/articles/intro.html","id":"custom-dictionaries","dir":"Articles","previous_headings":"Hunspell Dictionaries","what":"Custom Dictionaries","title":"The hunspell package: High-Performance Stemmer, Tokenizer, and Spell Checker for R","text":"system provide standard dictionaries need download . lot places provide quality dictionaries. SCOWL OpenOffice LibreOffice titoBouzout wooorm OS-X recommended put files ~/Library/Spelling/ /Library/Spelling/. However can also put project working directory, standard locations. wish store dictionaries somewhere else, can make hunspell find setting DICPATH environment variable. hunspell:::dicpath() shows locations system searches:","code":"Sys.setenv(DICPATH = \"/my/custom/hunspell/dir\") hunspell:::dicpath() [1] \"/my/custom/hunspell/dir\"                      [2] \"/usr/local/lib/R/site-library/hunspell/dict\"  [3] \"/github/home/Library/Spelling\"                [4] \"/usr/local/share/hunspell\"                    [5] \"/usr/local/share/myspell\"                     [6] \"/usr/local/share/myspell/dicts\"               [7] \"/usr/share/hunspell\"                          [8] \"/usr/share/myspell\"                           [9] \"/usr/share/myspell/dicts\"                    [10] \"/Library/Spelling\"                           [11] \"/dictionaries\""},{"path":"https://docs.ropensci.org/hunspell/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jeroen Ooms. Author, maintainer. Authors libhunspell. Copyright holder.            see AUTHORS file","code":""},{"path":"https://docs.ropensci.org/hunspell/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ooms J (2024). hunspell: High-Performance Stemmer, Tokenizer, Spell Checker. R package version 3.0.3, https://docs.ropensci.org/hunspell/https://ropensci.r-universe.dev/hunspell.","code":"@Manual{,   title = {hunspell: High-Performance Stemmer, Tokenizer, and Spell Checker},   author = {Jeroen Ooms},   year = {2024},   note = {R package version 3.0.3},   url = {https://docs.ropensci.org/hunspell/ https://ropensci.r-universe.dev/hunspell}, }"},{"path":"https://docs.ropensci.org/hunspell/index.html","id":"ropensci-the-hunspell-package","dir":"","previous_headings":"","what":"High-Performance Stemmer, Tokenizer, and Spell Checker","title":"High-Performance Stemmer, Tokenizer, and Spell Checker","text":"High-Performance Stemmer, Tokenizer, Spell Checker R  Low level spell checker morphological analyzer based famous hunspell library https://hunspell.github.io. package can analyze check individual words well tokenize text, latex, html xml documents. user-friendly interface use ‘spelling’ package builds package utilities automate checking files, documentation vignettes common formats.","code":""},{"path":"https://docs.ropensci.org/hunspell/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"High-Performance Stemmer, Tokenizer, and Spell Checker","text":"package includes bundled version libhunspell longer depends external system libraries:","code":"install.packages(\"hunspell\")"},{"path":"https://docs.ropensci.org/hunspell/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"High-Performance Stemmer, Tokenizer, and Spell Checker","text":"R package: - Blog post: Hunspell: Spell Checker Text Parser R - Blog post: Stemming Spell Checking R","code":""},{"path":"https://docs.ropensci.org/hunspell/index.html","id":"hello-world","dir":"","previous_headings":"","what":"Hello World","title":"High-Performance Stemmer, Tokenizer, and Spell Checker","text":"spelling package uses package spell R package documentation:","code":"# Check individual words words <- c(\"beer\", \"wiskey\", \"wine\") correct <- hunspell_check(words) print(correct)  # Find suggestions for incorrect words hunspell_suggest(words[!correct])  # Extract incorrect from a piece of text bad <- hunspell(\"spell checkers are not neccessairy for langauge ninja's\") print(bad[[1]]) hunspell_suggest(bad[[1]])  # Stemming words <- c(\"love\", \"loving\", \"lovingly\", \"loved\", \"lover\", \"lovely\", \"love\") hunspell_stem(words) hunspell_analyze(words) # Spell check a package library(spelling) spell_check_package(\"~/mypackage\")"},{"path":"https://docs.ropensci.org/hunspell/reference/hunspell.html","id":null,"dir":"Reference","previous_headings":"","what":"Hunspell Spell Checking and Morphological Analysis — hunspell","title":"Hunspell Spell Checking and Morphological Analysis — hunspell","text":"hunspell function high-level wrapper finding spelling errors within text document. takes character vector text (plain, latex, man, html xml format), parses words returns list incorrect words line. effectively combines hunspell_parse hunspell_check single step. functions package operate individual words, see details.","code":""},{"path":"https://docs.ropensci.org/hunspell/reference/hunspell.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hunspell Spell Checking and Morphological Analysis — hunspell","text":"","code":"hunspell(   text,   format = c(\"text\", \"man\", \"latex\", \"html\", \"xml\"),   dict = dictionary(\"en_US\"),   ignore = en_stats )  hunspell_parse(   text,   format = c(\"text\", \"man\", \"latex\", \"html\", \"xml\"),   dict = dictionary(\"en_US\") )  hunspell_check(words, dict = dictionary(\"en_US\"))  hunspell_suggest(words, dict = dictionary(\"en_US\"))  hunspell_analyze(words, dict = dictionary(\"en_US\"))  hunspell_stem(words, dict = dictionary(\"en_US\"))  hunspell_info(dict = dictionary(\"en_US\"))  dictionary(lang = \"en_US\", affix = NULL, add_words = NULL, cache = TRUE)  list_dictionaries()"},{"path":"https://docs.ropensci.org/hunspell/reference/hunspell.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hunspell Spell Checking and Morphological Analysis — hunspell","text":"text character vector arbitrary input text format input format; supported parsers text, latex, man, xml html. dict dictionary object string can passed dictionary. ignore character vector additional approved words added dictionary words character vector individual words spell check lang dictionary file language, see details affix file path corresponding affix file. NULL assumed path dict extension .aff. add_words character vector additional words add dictionary cache speed loading dictionaries caching","code":""},{"path":"https://docs.ropensci.org/hunspell/reference/hunspell.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hunspell Spell Checking and Morphological Analysis — hunspell","text":"Hunspell uses special dictionary format defines stems affixes valid given language. hunspell_analyze function shows word breaks valid stem plus affix. hunspell_stem function similar returns valid stems given word. Stemming can used summarize text (e.g wordcloud). hunspell_check function takes vector individual words tests one correctness. Finally hunspell_suggest used suggest correct alternatives (incorrect) input word. spell checking usually done document, package includes parsers extract words various common formats. hunspell_parse can parse plain-text, latex man format. R also built-parsers RdTextFilter SweaveTeXFilter, see also ?aspell. package searches dictionaries working directory well standard system locations. list_dictionaries provides list dictionaries can find. Additional search paths can specified setting DICPATH environment variable. US English dictionary (en_US) included package; dictionaries need installed system. operating systems already include compatible dictionaries names hunspell-en-gb myspell-en-gb. manually install dictionaries, copy corresponding .aff .dic file ~/Library/Spelling custom directory specified DICPATH. Alternatively can pass entire path .dic file dict parameter. popular sources dictionaries SCOWL, OpenOffice, debian, github/titoBouzout github/wooorm. Note hunspell uses iconv convert input text encoding used dictionary. fail text contains characters unsupported particular encoding. reason UTF-8 dictionaries preferable legacy 8-bit dictionaries.","code":""},{"path":"https://docs.ropensci.org/hunspell/reference/hunspell.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hunspell Spell Checking and Morphological Analysis — hunspell","text":"","code":"# Check individual words words <- c(\"beer\", \"wiskey\", \"wine\") correct <- hunspell_check(words) print(correct) #> [1]  TRUE FALSE  TRUE  # Find suggestions for incorrect words hunspell_suggest(words[!correct]) #> [[1]] #> [1] \"whiskey\"  \"whiskery\" #>   # Extract incorrect from a piece of text bad <- hunspell(\"spell checkers are not neccessairy for langauge ninja's\") print(bad[[1]]) #> [1] \"neccessairy\" \"langauge\"    hunspell_suggest(bad[[1]]) #> [[1]] #> [1] \"necessary\"   \"necessarily\" #>  #> [[2]] #> [1] \"language\" \"melange\"  #>   # Stemming words <- c(\"love\", \"loving\", \"lovingly\", \"loved\", \"lover\", \"lovely\", \"love\") hunspell_stem(words) #> [[1]] #> [1] \"love\" #>  #> [[2]] #> [1] \"loving\" \"love\"   #>  #> [[3]] #> [1] \"loving\" #>  #> [[4]] #> [1] \"loved\" \"love\"  #>  #> [[5]] #> [1] \"lover\" \"love\"  #>  #> [[6]] #> [1] \"lovely\" \"love\"   #>  #> [[7]] #> [1] \"love\" #>  hunspell_analyze(words) #> [[1]] #> [1] \" st:love\" #>  #> [[2]] #> [1] \" st:loving\"    \" st:love fl:G\" #>  #> [[3]] #> [1] \" st:loving fl:Y\" #>  #> [[4]] #> [1] \" st:loved\"     \" st:love fl:D\" #>  #> [[5]] #> [1] \" st:lover\"     \" st:love fl:R\" #>  #> [[6]] #> [1] \" st:lovely\"    \" st:love fl:Y\" #>  #> [[7]] #> [1] \" st:love\" #>   # Check an entire latex document tmpfile <- file.path(tempdir(), \"1406.4806v1.tar.gz\") download.file(\"https://arxiv.org/e-print/1406.4806v1\", tmpfile,  mode = \"wb\") untar(tmpfile, exdir = tempdir()) text <- readLines(file.path(tempdir(), \"content.tex\"), warn = FALSE) bad_words <- hunspell(text, format = \"latex\") sort(unique(unlist(bad_words))) #>  [1] \"CORBA\"             \"CTRL\"              \"DCOM\"              #>  [4] \"DOM\"               \"DSL\"               \"ESC\"               #>  [7] \"JRI\"               \"NaN\"               \"OAuth\"             #> [10] \"OpenCPU\"           \"RInside\"           \"RPC\"               #> [13] \"RProtoBuf\"         \"RStudio\"           \"Reproducibility\"   #> [16] \"RinRuby\"           \"Rserve\"            \"SIGINT\"            #> [19] \"STATA\"             \"STDOUT\"            \"Stateful\"          #> [22] \"auth\"              \"cpu\"               \"cran\"              #> [25] \"cron\"              \"css\"               \"csv\"               #> [28] \"de\"                \"dec\"               \"decompositions\"    #> [31] \"dir\"               \"eol\"               \"facto\"             #> [34] \"grDevices\"         \"httpuv\"            \"ignorable\"         #> [37] \"interoperable\"     \"js\"                \"json\"              #> [40] \"jsonlite\"          \"knitr\"             \"md\"                #> [43] \"memcached\"         \"mydata\"            \"myfile\"            #> [46] \"nondegenerateness\" \"ocpu\"              \"opencpu\"           #> [49] \"pandoc\"            \"pb\"                \"php\"               #> [52] \"png\"               \"prescripted\"       \"priori\"            #> [55] \"protobuf\"          \"rApache\"           \"rda\"               #> [58] \"rds\"               \"reproducibility\"   \"rlm\"               #> [61] \"rmd\"               \"rnorm\"             \"rnw\"               #> [64] \"rpy\"               \"saveRDS\"           \"scalability\"       #> [67] \"scalable\"          \"schemas\"           \"se\"                #> [70] \"sep\"               \"stateful\"          \"statefulness\"      #> [73] \"stdout\"            \"suboptimal\"        \"svg\"               #> [76] \"sweave\"            \"tex\"               \"texi\"              #> [79] \"tmp\"               \"toJSON\"            \"urlencoded\"        #> [82] \"www\"               \"xyz\"                # Summarize text by stems (e.g. for wordcloud) allwords <- hunspell_parse(text, format = \"latex\") stems <- unlist(hunspell_stem(unlist(allwords))) words <- head(sort(table(stems), decreasing = TRUE), 200)"}]
